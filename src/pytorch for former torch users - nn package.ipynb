{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.pool1(F.relu(self.conv1(input)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTConvNet(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MNISTConvNet()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 28, 28)\n",
    "out = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0971,  0.0000,  0.0027,  0.0000,  0.0606,  0.0245,  0.0138,\n",
       "          0.1563,  0.0344,  0.0944]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = torch.tensor([3], dtype=torch.long)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "err = loss_fn(out, target)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3522)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       [[[[-0.0924,  0.6788, -0.3091, -1.1697, -0.6006],\n",
       "          [ 0.0327, -1.8250,  1.1705,  0.4314, -0.1080],\n",
       "          [-0.3117,  1.2235,  0.2890, -0.8914,  0.3482],\n",
       "          [-1.4294,  1.0099,  1.1901, -1.1482,  0.9309],\n",
       "          [-0.9081, -0.3514, -1.5364,  0.2472, -0.8223]]],\n",
       "\n",
       "\n",
       "        [[[-0.3293,  1.4851, -0.3353, -0.0441, -0.9048],\n",
       "          [ 0.1503, -1.1915, -1.1917,  0.4583, -1.3083],\n",
       "          [ 0.1321,  0.2493,  0.4980, -0.2893, -1.8903],\n",
       "          [ 0.1883,  1.2472,  0.0794, -0.9436,  0.2583],\n",
       "          [-0.0893,  0.4557, -0.6890,  1.1562, -0.4931]]],\n",
       "\n",
       "\n",
       "        [[[ 0.9244,  1.1569,  0.2159, -0.1867, -0.3201],\n",
       "          [-1.9751,  0.3393,  1.1108,  0.9333,  0.8667],\n",
       "          [ 0.8876,  0.4905,  0.5255,  0.5335, -0.9599],\n",
       "          [ 0.2371, -1.0396,  0.4625, -1.8430, -0.7134],\n",
       "          [-1.1961,  1.2138,  2.0265,  0.8317,  0.1822]]],\n",
       "\n",
       "\n",
       "        [[[ 0.7619,  0.8316, -0.5600, -1.0744,  1.3814],\n",
       "          [ 0.4620,  2.1488, -0.2455, -1.8019, -0.4913],\n",
       "          [ 1.6767, -0.8040,  0.9203,  1.3121, -0.8584],\n",
       "          [-1.4213, -0.7698, -0.7598, -1.0156,  1.8237],\n",
       "          [-1.0381, -0.8082,  0.0920, -0.5261, -1.6033]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1785,  0.4426,  0.9351, -0.5318,  0.1199],\n",
       "          [-0.6229,  1.4620, -0.9308,  1.2292,  0.0148],\n",
       "          [ 0.2206, -0.1113, -0.0419, -0.6552,  0.3010],\n",
       "          [ 0.2937,  0.0188, -1.8965,  1.3837, -1.6096],\n",
       "          [ 0.8781,  0.5971, -0.2042, -0.2086,  0.7301]]],\n",
       "\n",
       "\n",
       "        [[[-0.4727,  1.0942, -0.3760,  0.3771, -0.1482],\n",
       "          [ 0.2288, -0.2623, -0.5660,  0.1825,  0.1799],\n",
       "          [ 0.0356,  0.3403,  1.4921, -1.1052, -1.5005],\n",
       "          [-0.5976, -1.5167,  0.9444,  0.6490, -0.5122],\n",
       "          [-0.3564,  1.5292,  0.6521, -1.0960, -0.3670]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2247,  0.0455,  0.2532,  1.0276,  1.1381],\n",
       "          [ 0.1052, -0.0359,  0.1842,  0.2222,  0.0468],\n",
       "          [-0.8257,  0.1699, -0.3086,  1.1385, -0.8743],\n",
       "          [-0.8796, -0.4959, -0.9129, -0.2902,  0.3872],\n",
       "          [-0.1120, -0.6647, -0.9593, -1.1934, -0.9827]]],\n",
       "\n",
       "\n",
       "        [[[-0.0146, -0.1166,  0.6149,  1.5847, -0.3642],\n",
       "          [-0.1095,  0.5792, -0.2350, -0.3424, -0.3703],\n",
       "          [ 0.1727,  0.4140, -0.2501, -0.0970,  0.1947],\n",
       "          [-0.7114,  0.3146, -0.4845,  1.5928,  0.4306],\n",
       "          [ 1.4676, -0.1937,  0.1526,  0.4461,  0.7793]]],\n",
       "\n",
       "\n",
       "        [[[ 0.6042, -0.6680,  0.1857, -0.1168, -0.7134],\n",
       "          [-1.6199,  0.1415,  0.7131,  0.9788, -0.3512],\n",
       "          [ 0.4952, -0.7556, -0.4468, -1.1224,  0.7557],\n",
       "          [-1.1377,  0.4245,  0.1241,  1.3601,  0.6598],\n",
       "          [ 0.1061,  0.6568,  0.6062,  0.3919, -0.6241]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2157, -0.7507, -0.6024, -0.7526, -0.0859],\n",
       "          [ 0.7234,  0.4793, -0.4207,  1.3345,  0.1152],\n",
       "          [ 0.0407,  1.3379, -0.3561, -0.3815,  0.7278],\n",
       "          [ 1.3913, -0.4386, -0.5346, -0.2723, -1.5709],\n",
       "          [ 0.2912, -0.3051,  0.1522, -0.7638,  0.5399]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 5, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight.grad.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9484)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight.data.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1325)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv1.weight.grad.data.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printnorm(self, input, output):\n",
    "    # input is a tuple of packed inputs\n",
    "    # output is a Tensor. output.data is the Tensor we are interested\n",
    "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "    print('')\n",
    "    print('input: ', type(input))\n",
    "    print('input[0]: ', type(input[0]))\n",
    "    print('output: ', type(output))\n",
    "    print('')\n",
    "    print('input size:', input[0].size())\n",
    "    print('output size:', output.data.size())\n",
    "    print('output norm:', output.data.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f4dfa798c88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.conv2.register_forward_hook(printnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([1, 10, 12, 12])\n",
      "output size: torch.Size([1, 20, 8, 8])\n",
      "output norm: tensor(13.3902)\n"
     ]
    }
   ],
   "source": [
    "out = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Conv2d forward\n",
      "\n",
      "input:  <class 'tuple'>\n",
      "input[0]:  <class 'torch.Tensor'>\n",
      "output:  <class 'torch.Tensor'>\n",
      "\n",
      "input size: torch.Size([1, 10, 12, 12])\n",
      "output size: torch.Size([1, 20, 8, 8])\n",
      "output norm: tensor(13.3902)\n",
      "Inside Conv2d backward\n",
      "Inside class:Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.Tensor'>\n",
      "\n",
      "grad_input size: torch.Size([1, 10, 12, 12])\n",
      "grad_output size: torch.Size([1, 20, 8, 8])\n",
      "grad_input norm: tensor(1.00000e-02 *\n",
      "       2.8586)\n",
      "Inside Conv2d backward\n",
      "Inside class:Conv2d\n",
      "\n",
      "grad_input:  <class 'tuple'>\n",
      "grad_input[0]:  <class 'torch.Tensor'>\n",
      "grad_output:  <class 'tuple'>\n",
      "grad_output[0]:  <class 'torch.Tensor'>\n",
      "\n",
      "grad_input size: torch.Size([1, 10, 12, 12])\n",
      "grad_output size: torch.Size([1, 20, 8, 8])\n",
      "grad_input norm: tensor(1.00000e-02 *\n",
      "       2.8586)\n"
     ]
    }
   ],
   "source": [
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
    "    print('Inside class:' + self.__class__.__name__)\n",
    "    print('')\n",
    "    print('grad_input: ', type(grad_input))\n",
    "    print('grad_input[0]: ', type(grad_input[0]))\n",
    "    print('grad_output: ', type(grad_output))\n",
    "    print('grad_output[0]: ', type(grad_output[0]))\n",
    "    print('')\n",
    "    print('grad_input size:', grad_input[0].size())\n",
    "    print('grad_output size:', grad_output[0].size())\n",
    "    print('grad_input norm:', grad_input[0].norm())\n",
    "\n",
    "\n",
    "net.conv2.register_backward_hook(printgradnorm)\n",
    "\n",
    "out = net(input)\n",
    "err = loss_fn(out, target)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, data_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        input_size = data_size + hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, data, last_hidden):\n",
    "        input = torch.cat((data, last_hidden), 1)\n",
    "        hidden = self.i2h(input)\n",
    "        output = self.h2o(hidden)\n",
    "        return hidden, output\n",
    "\n",
    "rnn = RNN(50, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "batch_size = 10\n",
    "TIMESTEPS = 5\n",
    "\n",
    "batch = torch.randn(batch_size, 50)\n",
    "hidden = torch.zeros(batch_size, 20)\n",
    "target = torch.zeros(batch_size, 10)\n",
    "\n",
    "loss = 0\n",
    "\n",
    "for t in range(TIMESTEPS):\n",
    "    hidden, output = rnn(batch, hidden)\n",
    "    loss += loss_fn(output, target)\n",
    "    \n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
